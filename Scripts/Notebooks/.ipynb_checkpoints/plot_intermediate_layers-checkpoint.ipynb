{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "from GravNN.Visualization.MapVisualization import MapVisualization\n",
    "from GravNN.Visualization.VisualizationBase import VisualizationBase\n",
    "\n",
    "from GravNN.GravityModels.SphericalHarmonics import SphericalHarmonics, get_sh_data\n",
    "from GravNN.Networks import utils\n",
    "from GravNN.Support.Grid import Grid\n",
    "from GravNN.Support.transformations import sphere2cart, cart2sph, invert_projection, project_acceleration\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from GravNN.CelestialBodies.Planets import Earth\n",
    "from GravNN.GravityModels.SphericalHarmonics import SphericalHarmonics, get_sh_data\n",
    "from GravNN.Networks import utils\n",
    "from GravNN.Networks.Plotting import Plotting\n",
    "from GravNN.Networks.Callbacks import CustomCallback\n",
    "from GravNN.Networks.Compression import (cluster_model, prune_model,\n",
    "                                         quantize_model)\n",
    "from GravNN.Networks.Model import CustomModel, load_config_and_model\n",
    "from GravNN.Networks.Networks import (DenseNet, InceptionNet, ResNet,\n",
    "                                      TraditionalNet)\n",
    "from GravNN.Networks.Plotting import Plotting\n",
    "from GravNN.Trajectories.DHGridDist import DHGridDist\n",
    "from GravNN.Trajectories.RandomDist import RandomDist\n",
    "from GravNN.Trajectories.ReducedGridDist import ReducedGridDist\n",
    "from GravNN.Trajectories.ReducedRandDist import ReducedRandDist\n",
    "from GravNN.Support.Grid import Grid\n",
    "from GravNN.Support.transformations import cart2sph, sphere2cart, project_acceleration\n",
    "from GravNN.Visualization.MapVisualization import MapVisualization\n",
    "from GravNN.Visualization.VisualizationBase import VisualizationBase\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_intermediate_layer(config, model, columns):\n",
    "    planet = Earth()\n",
    "    density_deg = 180\n",
    "    traj = DHGridDist(planet, planet.radius, degree=density_deg)\n",
    "\n",
    "    x_transformer = config['x_transformer'][0]\n",
    "    a_transformer = config['a_transformer'][0]\n",
    "\n",
    "    x = x_transformer.transform(traj.positions)\n",
    "\n",
    "    mapUnit = 'mGal'\n",
    "    map_vis = MapVisualization(mapUnit)\n",
    "    plt.rc('text', usetex=False)\n",
    "    for layer_i in range(0, 10):\n",
    "        map_vis.newFig()\n",
    "        i = 0\n",
    "        new_model = tf.keras.Model(model.network.inputs, model.network.layers[layer_i].output)\n",
    "        basis_functions = new_model(x)\n",
    "        output = np.zeros(np.shape(x))\n",
    "        rows, cols = int(np.ceil(np.shape(basis_functions)[1]/columns)), columns\n",
    "        if layer_i == 0 or layer_i == 9:\n",
    "            rows = 3\n",
    "            cols = 1\n",
    "        plt.subplot(rows, cols, 1)\n",
    "        for basis_function in np.transpose(basis_functions):\n",
    "            plt.subplot(rows, cols, 1+int(i))\n",
    "\n",
    "            output[:,0] = basis_function\n",
    "\n",
    "            grid_pred = Grid(trajectory=traj, accelerations=output)\n",
    "\n",
    "            im = map_vis.new_map(grid_pred.total)\n",
    "            plt.xlabel(None)\n",
    "            plt.ylabel(None)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            i += 1\n",
    "        plt.suptitle(\"Layer:\" + str(layer_i))\n",
    "\n",
    "    map_vis.newFig()\n",
    "    grid_pred = Grid(trajectory=traj, accelerations=model.network(x))\n",
    "    im = map_vis.new_map(grid_pred.total)\n",
    "    plt.title(\"Final Acceleration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config_and_model(model_id, df_file):\n",
    "    # Get the parameters and stats for a given run\n",
    "    # If the dataframe hasn't been loaded\n",
    "    if type(df_file) == str:\n",
    "        config = utils.get_df_row(model_id, df_file)\n",
    "    else:\n",
    "        # If the dataframe has already been loaded\n",
    "        config = df_file[model_id == df_file['id']].to_dict()\n",
    "        for key, value in config.items():\n",
    "            config[key] = list(value.values())\n",
    "\n",
    "    # Reinitialize the model\n",
    "    network = tf.keras.models.load_model('C:\\\\Users\\\\John\\\\Documents\\\\Research\\\\ML_Gravity' + \"/Data/Networks/\"+str(model_id)+\"/network\")\n",
    "    model = CustomModel(config, network)\n",
    "    if 'adam' in config['optimizer'][0]:\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "    elif 'rms' in config['optimizer'][0]:\n",
    "        optimizer = tf.keras.optimizers.RMSprop()\n",
    "    else:\n",
    "        exit(\"No Optimizer Found\")\n",
    "    model.compile(optimizer=optimizer, loss='mse') #! Check that this compile is even necessary\n",
    "\n",
    "    return config, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file = 'C:\\\\Users\\\\John\\\\Documents\\\\Research\\\\ML_Gravity\\\\Data\\\\Dataframes\\\\hyperparameter_v3.data'\n",
    "\n",
    "#df = pd.read_pickle(df_file)#[3:]#.sort_values(by='params')[2:]##[:2]\n",
    "df = pd.read_pickle(df_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Performer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: C:/Data/Networks/2459271.5027662036/network/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-c50a8d540131>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mid_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_config_and_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplot_intermediate_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-ddc5a3db2a1a>\u001b[0m in \u001b[0;36mload_config_and_model\u001b[1;34m(model_id, df_file)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Reinitialize the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\John\\\\Documents\\\\Research\\\\ML_Gravity'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"/Data/Networks/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/network\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'adam'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'optimizer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\john\\documents\\research\\venv\\tf2env\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\john\\documents\\research\\venv\\tf2env\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    112\u001b[0m                   (export_dir,\n\u001b[0;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: C:/Data/Networks/2459271.5027662036/network/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "ids = df['id'].values\n",
    "id_value, columns = ids[0], 6\n",
    "\n",
    "model_id = id_value\n",
    "config, model = load_config_and_model(model_id, df)\n",
    "plot_intermediate_layer(config, model, columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worst Performer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df['id'].values\n",
    "id_value, columns = ids[-1], 6\n",
    "\n",
    "model_id = id_value\n",
    "config, model = load_config_and_model(model_id, df)\n",
    "plot_intermediate_layer(config, model, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='dropout', ascending=False)\n",
    "ids = df['id'].values\n",
    "id_value, columns = ids[0], 6\n",
    "\n",
    "model_id = id_value\n",
    "config, model = load_config_and_model(model_id, df)\n",
    "plot_intermediate_layer(config, model, columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
