{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit270b3bd8e46b448e82a3a294e684538e",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Great\nEven Better\n"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import talos\n",
    "import tensorflow as tf\n",
    "\n",
    "#from tensorflow.keras.utils.layer_utils import count_params\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from talos import Analyze, Deploy, Evaluate, Predict, Reporting, Restore, Scan\n",
    "from tensorflow.keras.optimizers import SGD, Adadelta, Adam, Nadam, RMSprop\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "sys.path.append('/Users/johnmartin/Documents/GraduateSchool/Research/GravityML/nnPosAcc/')\n",
    "\n",
    "print(\"Great\")\n",
    "from CelestialBodies.Planets import Earth\n",
    "print(\"Even Better\")\n",
    "Earth()\n",
    "from GravityModels.NN_Base import NN_Base\n",
    "from GravityModels.NNSupport.NN_hyperparam import NN_hyperparam\n",
    "from GravityModels.SphericalHarmonics import SphericalHarmonics\n",
    "from GravNN.Preprocessors.MaxAbsTransform import MaxAbsTransform\n",
    "from GravNN.Preprocessors.MinMaxTransform import MinMaxTransform\n",
    "from GravNN.Preprocessors.RobustTransform import RobustTransform\n",
    "from GravNN.Preprocessors.MinMaxStandardTransform  import MinMaxStandardTransform\n",
    "from GravNN.Preprocessors.StandardTransform import StandardTransform\n",
    "from GravNN.Support.transformations import (cart2sph,\n",
    "                                     check_fix_radial_precision_errors,\n",
    "                                     project_acceleration, sphere2cart)\n",
    "from GravNN.Trajectories.DHGridDist import DHGridDist\n",
    "from GravNN.Trajectories.RandomDist import RandomDist\n",
    "from GravNN.Trajectories.UniformDist import UniformDist\n",
    "from GravNN.Visualization.Grid import Grid\n",
    "from GravNN.Visualization.MapVisualization import MapVisualization\n",
    "from talos import Analyze\n",
    "import pandas as pd\n",
    "\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "# os.environ[\"RUNFILES_DIR\"] = \"/Users/johnmartin/Library/Python/3.7/share/plaidml\"# plaidml might exist in different location. Look for \"/usr/local/share/plaidml\" and replace in above path\n",
    "# os.environ[\"PLAIDML_NATIVE_PATH\"] = \"/Users/johnmartin/Library/Python/3.7/lib/libplaidml.dylib\" # libplaidml.dylib might exist in different location. Look for \"/usr/local/lib/libplaidml.dylib\" and replace in above path\n",
    "\n",
    "seed(1)\n",
    "\n",
    "def plot_metrics(history, save_location=None):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    if save_location is not None:\n",
    "        plt.savefig(plt.gcf(), save_location + \"loss.pdf\")\n",
    "    return\n",
    "\n",
    "def calc_metrics(meas, truth):\n",
    "    error_inst = abs(np.divide((meas - truth),truth)*100)\n",
    "    mse = np.square(meas - truth).mean(axis=None)\n",
    "    rmse = np.sqrt(mse).mean(axis=None)\n",
    "    print(\"Avg: \" + str(np.average(error_inst)))\n",
    "    print(\"Med: \" + str(np.median(error_inst)))\n",
    "    print(\"MSE: \" + str(mse))\n",
    "    print(\"RMSE: \" + str(rmse))\n",
    "    return error_inst, mse, rmse\n",
    "\n",
    "\n",
    "def compute_error(model, \n",
    "                                    x_train_encode, y_train_encode,\n",
    "                                    x_test_encode, y_test_encode\n",
    "                                    , preprocessor):\n",
    "\n",
    "    print(\"TRAINING ENCODE\")\n",
    "    pred_encode = model.predict(x_train_encode)\n",
    "    error_inst, mse, rmse = calc_metrics(pred_encode, y_train_encode)\n",
    "    \n",
    "    print(\"TRAINING DECODE\")\n",
    "    prediction = model.predict(x_train_encode)\n",
    "    x_decode, pred_decode = preprocessor.invert_transform(x_train_encode, prediction)\n",
    "    x_decode, y_train_decode = preprocessor.invert_transform(x_train_encode, y_train_encode)\n",
    "    error_inst, mse, rmse = calc_metrics(pred_decode, y_train_decode)\n",
    "\n",
    "    print(\"TESTING ENCODE\")\n",
    "    prediction = model.predict(x_test_encode)\n",
    "    error_inst, mse, rmse = calc_metrics(prediction, y_test_encode)\n",
    "    \n",
    "    print(\"TESTING DECODE\")\n",
    "    prediction = model.predict(x_test_encode)\n",
    "    x_decode, pred_decode = preprocessor.invert_transform(x_test_encode, prediction)\n",
    "    x_decode, y_test_decode = preprocessor.invert_transform(x_test_encode, y_test_encode)\n",
    "    error_inst, mse, rmse = calc_metrics(pred_decode, y_test_decode)\n",
    "\n",
    "    print(\"MAX DECODE PRED:\" + str(pred_decode.max()))\n",
    "    print(\"MAX DECODE TRUTH:\"  + str(y_train_decode.max()))\n",
    "    print(\"MIN DECODE PRED:\"  + str(pred_decode.min()))\n",
    "    print(\"MIN DECODE TRUTH:\"  + str(y_train_decode.min()))\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The total number of points is not a perfect square\nThe total number of points changed to 259200\n[<tensorflow.python.keras.callbacks.TensorBoard object at 0x146a80790>]\nFound existing acceleration.data at /Users/johnmartin/Documents/GraduateSchool/Research/GravityML/nnPosAcc/Trajectories/TrajectoryBase/../../Files/Trajectories/RandomDist/earthN_259200_RadBounds[6378136.6, 6383136.6]/SphericalHarmonics_EGM2008_to2190_TideFree_E_1000/\nFound existing acceleration.data at /Users/johnmartin/Documents/GraduateSchool/Research/GravityML/nnPosAcc/Trajectories/TrajectoryBase/../../Files/Trajectories/RandomDist/earthN_259200_RadBounds[6378136.6, 6383136.6]/SphericalHarmonics_EGM2008_to2190_TideFree_E_2/\nEpoch 1/30\n18144/18144 [==============================] - 41s 2ms/step - loss: 1.0002 - mse: 1.0002 - mae: 0.7015 - val_loss: 1.0038 - val_mse: 1.0038 - val_mae: 0.7022\nEpoch 2/30\n18144/18144 [==============================] - 44s 2ms/step - loss: 1.0002 - mse: 1.0002 - mae: 0.7015 - val_loss: 1.0036 - val_mse: 1.0036 - val_mae: 0.7023\nEpoch 3/30\n18144/18144 [==============================] - 49s 3ms/step - loss: 1.0001 - mse: 1.0001 - mae: 0.7015 - val_loss: 1.0037 - val_mse: 1.0037 - val_mae: 0.7019\nEpoch 4/30\n18144/18144 [==============================] - 39s 2ms/step - loss: 1.0001 - mse: 1.0001 - mae: 0.7014 - val_loss: 1.0037 - val_mse: 1.0037 - val_mae: 0.7023\nEpoch 5/30\n 4643/18144 [======>.......................] - ETA: 28s - loss: 1.0077 - mse: 1.0077 - mae: 0.7031"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6907a13ab084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_hyperparam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# save_location=save_location)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;31m#hist, model = NN_hyperparam(x_train, y_train, x_train, y_train, params, verbose=1) # Test on the same data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GraduateSchool/Research/GravityML/nnPosAcc/GravityModels/NNSupport/NN_hyperparam.py\u001b[0m in \u001b[0;36mNN_hyperparam\u001b[0;34m(x_train, y_train, x_val, y_val, params, verbose, save_location)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 callbacks=params['callbacks'])\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0;31m#callbacks=[talos.utils.live()])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;31m#callbacks=[earlyStop])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0mbatch_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m       \u001b[0mbatch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1975\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'batch_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1977\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_increment_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_run_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1978\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_tracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m       control_flow_ops.cond(\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_increment_step\u001b[0;34m(self, writer_name)\u001b[0m\n\u001b[1;32m   1905\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_batches_seen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwriter_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1907\u001b[0;31m       \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1908\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_batches_seen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwriter_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(self, delta, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    813\u001b[0m           name=name)\n\u001b[1;32m    814\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_add_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0massign_add_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_lazy_read\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0min_graph_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_graph_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0mdeleter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_deleter\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_graph_mode\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m         parent_op=op, unique_id=self._unique_id)\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, dtype, shape, in_graph_mode, deleter, parent_op, unique_id)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0mhandle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0munique_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_deleter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeleter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m         graph_element=graph_element)\n\u001b[0m\u001b[1;32m   1861\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, shape, dtype, handle, constraint, synchronization, aggregation, distribute_strategy, name, unique_id, handle_name, graph_element, initial_value, initializer_op, is_initialized_op, cached_value, save_slice_info, handle_deleter, caching_device, **unused_kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mdeduplicate\u001b[0m \u001b[0mcopying\u001b[0m \u001b[0mthrough\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mSwitch\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m \u001b[0mconditional\u001b[0m \u001b[0mstatements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \"\"\"\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_graph_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     synchronization, aggregation, trainable = (\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minit_scope\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5501\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5502\u001b[0m     \u001b[0;31m# Fastpath.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5503\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5504\u001b[0m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5505\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# do not keep args and kwds alive unnecessarily\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# they are only needed for recreation, which is not possible anymore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Loads all parameters tested and find the one with the lowest validation loss\n",
    "Populate a network with those parameters and retrain\n",
    "\"\"\"\n",
    "planet = Earth()\n",
    "\n",
    "# directory = \"./Hyperparams/UniformDist/MinMaxTransform/259200/\"\n",
    "# cases = ['071320150333.csv', '071320150753.csv', '071320150805.csv' , \n",
    "#                 '071420143549.csv', '071420143558.csv', '071420143613.csv']\n",
    "# preprocessor = MinMaxTransform()\n",
    "# trajectory = UniformDist(planet, planet.radius, point_count)\n",
    "\n",
    "case = 6 # moved to main at bottom\n",
    "directory = \"./Hyperparams/RandomDist/MinMaxStandardTransform/259200/\"\n",
    "cases = ['072120093037.csv', '072120093056.csv', '072120093113.csv' , \n",
    "                '072120093251.csv', '072120093223.csv', '072120093140.csv']\n",
    "preprocessor = MinMaxStandardTransform()\n",
    "\n",
    "#point_count = 180*180*2\n",
    "point_count = 259200 # 360*360*2\n",
    "#point_count = 720*720*2\n",
    "trajectory = RandomDist(planet, [planet.radius, planet.radius+5000.0], point_count)\n",
    "#trajectory = RandomDist(planet, [planet.radius+330.0*1000-2500 , planet.radius + 330.0*1000+2500], point_count) #LEO\n",
    "epochs = 30\n",
    "bs = 50\n",
    "plot_maps = True\n",
    "\n",
    "experiment_dir = trajectory.trajectory_name + preprocessor.__class__.__name__\n",
    "experiment_dir =  experiment_dir.replace(', ', '_')\n",
    "experiment_dir =  experiment_dir.replace('[', '_')\n",
    "experiment_dir =  experiment_dir.replace(']', '_')\n",
    "\n",
    "\n",
    "\n",
    "save_location = \"./Files/Final_NN/\" + experiment_dir + \"/case_\"+str(case) + \"/\"\n",
    "a = Analyze(directory + 'case_' + str(case) + '/' + cases[case-1]) \n",
    "\n",
    "\n",
    "\n",
    "df = a.data\n",
    "run = df[df['val_loss'] == df['val_loss'].min()]\n",
    "params = run.iloc[0].to_dict()\n",
    "params['epochs'] = epochs\n",
    "params['batch_size'] = 10#bs\n",
    "params['optimizer'] = eval(params['optimizer'].split('.')[-1].split('\\'')[0]) #Nadam\n",
    "#params['kernel_initializer'] = eval(params['kernel_initializer'])\n",
    "if eval(params['kernel_regularizer']) is None:\n",
    "    params['kernel_regularizer'] = None\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs', write_graph=True, write_images=True, histogram_freq=1)\n",
    "params['callbacks'] = [tensorboard_callback]\n",
    "print(params['callbacks'])\n",
    "params['first_unit'] = 256\n",
    "params['first_neuron'] = 128\n",
    "params['hidden_layers'] = 10\n",
    "params['activation'] = 'elu'\n",
    "params['kernel_initializer'] = tf.keras.initializers.GlorotNormal()\n",
    "'''\n",
    "params['kernel_regularizer'] = 'l2'\n",
    "params['first_unit'] = 256\n",
    "params['first_neuron'] = 128\n",
    "params['hidden_layers'] = 0\n",
    "params['dropout'] = 0.4\n",
    "params['batch_size'] = 10\n",
    "params['lr'] = 0.1\n",
    "params['epochs'] = 50\n",
    "params['optimizer'] = Adadelta\n",
    "params['losses'] = 'mean_absolute_error'\n",
    "params['losses'] = 'mean_absolute_percentage_error'\n",
    "params['optimizer'] = SGD\n",
    "params['losses'] = 'mean_absolute_error'# 'mean_squared_error'\n",
    "'''\n",
    "\n",
    "\n",
    "sh_file = planet.sh_hf_file\n",
    "max_deg = 1000\n",
    "\n",
    "gravityModelMap = SphericalHarmonics(sh_file, degree=max_deg, trajectory=trajectory)\n",
    "gravityModelMap.load() \n",
    "gravityModelMapC20 = SphericalHarmonics(sh_file, degree=2, trajectory=trajectory)\n",
    "gravityModelMapC20.load() \n",
    "gravityModelMap.accelerations -= gravityModelMapC20.accelerations\n",
    "\n",
    "pos_sphere = cart2sph(trajectory.positions)\n",
    "pos_sphere = check_fix_radial_precision_errors(pos_sphere)\n",
    "acc_proj = project_acceleration(pos_sphere, gravityModelMap.accelerations)\n",
    "\n",
    "preprocessor.percentTest = 0.3\n",
    "preprocessor.split(pos_sphere, acc_proj)\n",
    "preprocessor.fit()\n",
    "x_train, x_val, y_train, y_val = preprocessor.apply_transform()\n",
    "#x_train, y_train = pos_sphere, acc_proj # don't even transform the data. \n",
    "# preprocessor = RobustTransform()\n",
    "# a = Analyze(\"./Hyperparams/Initial_Search/Uniform/070820134910.csv\") # Uniform Robust 1\n",
    "\n",
    "\n",
    "hist, model = NN_hyperparam(x_train, y_train, x_val, y_val, params, verbose=1)# save_location=save_location)\n",
    "#hist, model = NN_hyperparam(x_train, y_train, x_train, y_train, params, verbose=1) # Test on the same data\n",
    "\n",
    "plot_metrics(hist)\n",
    "compute_error(model, \n",
    "                            x_train, y_train,\n",
    "                            x_val, y_val\n",
    "                            , preprocessor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'DHGridDist' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-29c071ceab55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmap_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDHGridDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplanet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplanet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m175\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msh_all_gravityModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSphericalHarmonics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_deg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msh_C20_gravityModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSphericalHarmonics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrue_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgravityModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msh_all_gravityModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msh_20_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgravityModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msh_C20_gravityModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DHGridDist' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "map_grid = DHGridDist(planet, planet.radius, degree=175)\n",
    "sh_all_gravityModel = SphericalHarmonics(sh_file, degree=max_deg, trajectory=map_grid)\n",
    "sh_C20_gravityModel = SphericalHarmonics(sh_file, degree=2, trajectory=map_grid)\n",
    "true_grid = Grid(gravityModel=sh_all_gravityModel)\n",
    "sh_20_grid = Grid(gravityModel=sh_C20_gravityModel)\n",
    "true_grid -= sh_20_grid #these values are projected\n",
    "nn = NN_Base(model, preprocessor, test_traj=map_grid)\n",
    "\n",
    "map_viz = MapVisualization(unit = 'mGal')\n",
    "grid = Grid(gravityModel=nn, override=True)\n",
    "#fig, ax = map_viz.plot_grid_mse(C100_grid, true_grid,vlim=[0, 2E-7])\n",
    "map_viz.plot_grid(grid.total, \"NN\")\n",
    "fig, ax = map_viz.plot_grid_rmse(grid, true_grid,vlim=[0, 40])\n",
    "\n",
    "# M_params = count_params(nn.model.trainable_weights)\n",
    "# print(\"Params: \" + str(M_params))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}